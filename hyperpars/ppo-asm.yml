# algo 
algo: "PPO"
total_timesteps: 5000000
algo_config:
    tensorboard_log: "../../../logs"
    normalize: true
    policy: 'MlpPolicy'
    batch_size: 256
    gamma: 0.9999
    learning_rate: !!float 7.77e-05
    ent_coef: 0.00429
    clip_range: 0.1
    gae_lambda: 0.9
    max_grad_norm: 5
    vf_coef: 0.19
    use_sde: True
    policy_kwargs: "dict(log_std_init=-3.29, ortho_init=False)"
    # policy: 'MlpPolicy'
    # use_sde: True
    # policy_kwargs: "dict(log_std_init=-3, net_arch=[400, 300])"
    # clip_range: 0.1

# env
env_id: "AsmEnv"
config: 
    observation_fn_id: 'observe_1o'
    n_observs: 1
    upow: 0.6
n_envs: 12

# io
repo: "cboettig/rl-ecology"
save_path: "../saved_agents"

# misc
id: "1o-upow0.6"
additional_imports: ["torch"]